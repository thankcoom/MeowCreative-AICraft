#!/usr/bin/env python3
"""
E-E-A-T åˆ†æå™¨ (Experience, Expertise, Authoritativeness, Trustworthiness)

é€™å€‹å·¥å…·è©•ä¼°æ–‡ç« å…§å®¹çš„ E-E-A-T å“è³ªï¼Œé€™æ˜¯ Google 2025 å¹´æœ€é‡è¦–çš„æ’åå› ç´ ã€‚

ç‰ˆæœ¬: 1.0.0
å»ºç«‹æ—¥æœŸ: 2025-11-04
ä½œè€…: å–µå“©æ–‡å‰µ AI å¯«æ‰‹ç³»çµ±åœ˜éšŠ
"""

import re
import json
import yaml
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict


@dataclass
class EEATScore:
    """E-E-A-T è©•åˆ†çµæœ"""
    experience: float  # ç¶“é©—åˆ†æ•¸ (0-100)
    expertise: float   # å°ˆæ¥­çŸ¥è­˜åˆ†æ•¸ (0-100)
    authoritativeness: float  # æ¬Šå¨æ€§åˆ†æ•¸ (0-100)
    trustworthiness: float    # å¯ä¿¡åº¦åˆ†æ•¸ (0-100)
    overall: float     # ç¸½åˆ† (0-100)

    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class EEATAnalysisResult:
    """E-E-A-T åˆ†æçµæœ"""
    scores: EEATScore
    strengths: List[str]
    weaknesses: List[str]
    recommendations: List[str]
    details: Dict
    analyzed_at: str


class EEATAnalyzer:
    """E-E-A-T å…§å®¹å“è³ªåˆ†æå™¨"""

    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾‘ï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨é è¨­é…ç½®
        """
        self.config = self._load_config(config_path)

    def _load_config(self, config_path: Optional[str]) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        if config_path and Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        else:
            # ä½¿ç”¨é è¨­é…ç½®
            return self._get_default_config()

    def _get_default_config(self) -> Dict:
        """å–å¾—é è¨­é…ç½®"""
        return {
            'weights': {
                'experience': 0.30,
                'expertise': 0.25,
                'authoritativeness': 0.20,
                'trustworthiness': 0.25
            },
            'thresholds': {
                'excellent': 85,
                'good': 70,
                'fair': 55,
                'poor': 40
            }
        }

    def analyze(self, content: str, experience_profile_path: Optional[str] = None) -> EEATAnalysisResult:
        """
        åˆ†ææ–‡ç« çš„ E-E-A-T å“è³ª

        Args:
            content: æ–‡ç« å…§å®¹ï¼ˆMarkdown æ ¼å¼ï¼‰
            experience_profile_path: ç”¨æˆ¶ç¶“é©—æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼Œä½†å¼·çƒˆå»ºè­°æä¾›ï¼‰

        Returns:
            E-E-A-T åˆ†æçµæœ
        """
        # è®€å–ç”¨æˆ¶ç¶“é©—æª”æ¡ˆ
        experience_data = None
        if experience_profile_path and Path(experience_profile_path).exists():
            with open(experience_profile_path, 'r', encoding='utf-8') as f:
                experience_data = f.read()

        # åˆ†æå„é …æŒ‡æ¨™
        experience_score, exp_details = self._analyze_experience(content, experience_data)
        expertise_score, exp_details_2 = self._analyze_expertise(content)
        authority_score, auth_details = self._analyze_authoritativeness(content)
        trust_score, trust_details = self._analyze_trustworthiness(content)

        # è¨ˆç®—ç¸½åˆ†
        weights = self.config['weights']
        overall = (
            experience_score * weights['experience'] +
            expertise_score * weights['expertise'] +
            authority_score * weights['authoritativeness'] +
            trust_score * weights['trustworthiness']
        )

        scores = EEATScore(
            experience=round(experience_score, 2),
            expertise=round(expertise_score, 2),
            authoritativeness=round(authority_score, 2),
            trustworthiness=round(trust_score, 2),
            overall=round(overall, 2)
        )

        # å½™æ•´å„ªç¼ºé»å’Œå»ºè­°
        strengths, weaknesses, recommendations = self._generate_insights(
            scores, exp_details, exp_details_2, auth_details, trust_details
        )

        # å½™æ•´è©³ç´°è³‡è¨Š
        details = {
            'experience': exp_details,
            'expertise': exp_details_2,
            'authoritativeness': auth_details,
            'trustworthiness': trust_details
        }

        return EEATAnalysisResult(
            scores=scores,
            strengths=strengths,
            weaknesses=weaknesses,
            recommendations=recommendations,
            details=details,
            analyzed_at=datetime.now().isoformat()
        )

    def _analyze_experience(self, content: str, experience_data: Optional[str]) -> Tuple[float, Dict]:
        """
        åˆ†æã€Œç¶“é©—ã€ç¶­åº¦

        æª¢æŸ¥é …ç›®ï¼š
        - æ˜¯å¦æœ‰ç¬¬ä¸€äººç¨±çš„çœŸå¯¦ç¶“é©—æ•˜è¿°
        - æ˜¯å¦æœ‰å…·é«”çš„æ™‚é–“ã€åœ°é»ã€æƒ…å¢ƒ
        - æ˜¯å¦æœ‰å€‹äººè¦‹è§£å’Œåæ€
        - æ˜¯å¦èˆ‡ experience_profile.md ä¸€è‡´
        """
        score = 0.0
        details = {
            'has_first_person': False,
            'has_specific_details': False,
            'has_personal_insights': False,
            'consistent_with_profile': None,
            'experience_indicators': []
        }

        # 1. æª¢æŸ¥ç¬¬ä¸€äººç¨±æ•˜è¿° (30åˆ†)
        first_person_patterns = [
            r'æˆ‘[ä½¿ç”¨é|è©¦é|ç™¼ç¾|æ³¨æ„åˆ°|ç¶“æ­·|é‡åˆ°]',
            r'ç•¶æˆ‘[é–‹å§‹|å˜—è©¦|ä½¿ç”¨]',
            r'æˆ‘çš„[ç¶“é©—|å¿ƒå¾—|è§€å¯Ÿ|ç™¼ç¾]',
            r'æ ¹æ“šæˆ‘çš„[å¯¦éš›|è¦ªèº«]'
        ]

        first_person_count = 0
        for pattern in first_person_patterns:
            matches = re.findall(pattern, content)
            first_person_count += len(matches)
            if matches:
                details['experience_indicators'].extend(matches[:2])  # è¨˜éŒ„å‰2å€‹ç¯„ä¾‹

        if first_person_count >= 5:
            score += 30
            details['has_first_person'] = True
        elif first_person_count >= 3:
            score += 20
            details['has_first_person'] = True
        elif first_person_count >= 1:
            score += 10
            details['has_first_person'] = True

        # 2. æª¢æŸ¥å…·é«”ç´°ç¯€ (30åˆ†)
        # æ™‚é–“åƒè€ƒ
        time_patterns = [
            r'\d+[å¹´å€‹å¤©é€±æœˆ]å‰',
            r'ä¸Š[å€‹é€±æœˆå¹´]',
            r'å»å¹´|ä»Šå¹´',
            r'20\d{2}å¹´',
            r'æœ€è¿‘|è¿‘æœŸ'
        ]
        time_count = sum(len(re.findall(p, content)) for p in time_patterns)

        # å…·é«”æ•¸å­—å’Œæ•¸æ“š
        specific_numbers = re.findall(r'\d+%|\d+å€|\d+å°æ™‚|\d+å¤©|\d+å€‹', content)

        # æƒ…å¢ƒæè¿°
        context_patterns = [
            r'åœ¨[ä½¿ç”¨|é–‹ç™¼|æ¸¬è©¦|éƒ¨ç½²].*æ™‚',
            r'ç•¶[é‡åˆ°|é¢å°|è™•ç†]',
            r'[å°ˆæ¡ˆ|ç³»çµ±|å·¥å…·]ä¸­'
        ]
        context_count = sum(len(re.findall(p, content)) for p in context_patterns)

        specificity_score = min(30, (time_count * 5 + len(specific_numbers) * 3 + context_count * 5))
        score += specificity_score
        details['has_specific_details'] = specificity_score > 15

        # 3. æª¢æŸ¥å€‹äººè¦‹è§£ (20åˆ†)
        insight_patterns = [
            r'æˆ‘[èªç‚º|è¦ºå¾—|å»ºè­°|æ¨è–¦]',
            r'å€‹äºº[çœ‹æ³•|è§€é»|å»ºè­°]',
            r'å€¼å¾—æ³¨æ„çš„æ˜¯',
            r'é—œéµ[åœ¨æ–¼|æ˜¯]'
        ]
        insight_count = sum(len(re.findall(p, content)) for p in insight_patterns)

        if insight_count >= 3:
            score += 20
            details['has_personal_insights'] = True
        elif insight_count >= 2:
            score += 15
            details['has_personal_insights'] = True
        elif insight_count >= 1:
            score += 10
            details['has_personal_insights'] = True

        # 4. èˆ‡ experience_profile ä¸€è‡´æ€§ (20åˆ†)
        if experience_data:
            # ç°¡å–®æª¢æŸ¥ï¼šæ˜¯å¦æœ‰ç¶“é©—æª”æ¡ˆä¸­æåˆ°çš„ä¸»é¡Œ
            consistency_score = self._check_experience_consistency(content, experience_data)
            score += consistency_score
            details['consistent_with_profile'] = consistency_score > 10
        else:
            # æ²’æœ‰ç¶“é©—æª”æ¡ˆï¼Œç„¡æ³•é©—è­‰ï¼Œçµ¦äºˆåŸºç¤åˆ†
            score += 10
            details['consistent_with_profile'] = None

        return min(100, score), details

    def _check_experience_consistency(self, content: str, experience_data: str) -> float:
        """æª¢æŸ¥å…§å®¹èˆ‡ç¶“é©—æª”æ¡ˆçš„ä¸€è‡´æ€§"""
        # æå–ç¶“é©—æª”æ¡ˆä¸­çš„ã€Œå¯å¯«å…§å®¹ã€
        can_write_section = re.search(r'## å¯å¯«å…§å®¹æ¸…å–®(.*?)##', experience_data, re.DOTALL)
        if not can_write_section:
            return 10  # ç„¡æ³•åˆ¤æ–·ï¼Œçµ¦äºˆåŸºç¤åˆ†

        can_write_topics = can_write_section.group(1)

        # æå–ã€Œä¸å¯å¯«å…§å®¹ã€
        cannot_write_section = re.search(r'## ä¸å¯å¯«å…§å®¹æ¸…å–®(.*?)(?:##|$)', experience_data, re.DOTALL)

        # ç°¡å–®ä¸€è‡´æ€§æª¢æŸ¥ï¼šå…§å®¹ä¸­æ˜¯å¦æåˆ°å¯å¯«ä¸»é¡Œ
        # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰è©²æ›´è¤‡é›œ
        if any(topic in content for topic in ['å¯¦éš›', 'ç¶“é©—', 'ä½¿ç”¨é', 'è©¦é']):
            return 20
        return 10

    def _analyze_expertise(self, content: str) -> Tuple[float, Dict]:
        """
        åˆ†æã€Œå°ˆæ¥­çŸ¥è­˜ã€ç¶­åº¦

        æª¢æŸ¥é …ç›®ï¼š
        - å…§å®¹æ·±åº¦ï¼ˆæ˜¯å¦æ·±å…¥æŠ€è¡“ç´°ç¯€ï¼‰
        - å°ˆæ¥­è¡“èªä½¿ç”¨æ­£ç¢ºæ€§
        - ç†è«–èˆ‡å¯¦è¸çµåˆ
        - ç¨‹å¼ç¢¼ç¯„ä¾‹å“è³ª
        """
        score = 0.0
        details = {
            'has_code_examples': False,
            'code_quality': 0,
            'technical_depth': 0,
            'theory_practice_balance': False,
            'professional_terms': []
        }

        # 1. ç¨‹å¼ç¢¼ç¯„ä¾‹ (30åˆ†)
        code_blocks = re.findall(r'```[\s\S]*?```', content)
        code_count = len(code_blocks)

        if code_count >= 3:
            score += 20
            details['has_code_examples'] = True

            # æª¢æŸ¥ç¨‹å¼ç¢¼å“è³ªï¼ˆæœ‰è¨»è§£ã€æœ‰èªªæ˜ï¼‰
            good_code = sum(1 for block in code_blocks if '#' in block or '"""' in block or '//' in block)
            if good_code >= code_count * 0.7:
                score += 10
                details['code_quality'] = 90
            elif good_code >= code_count * 0.5:
                score += 5
                details['code_quality'] = 70
            else:
                details['code_quality'] = 50
        elif code_count >= 1:
            score += 10
            details['has_code_examples'] = True
            details['code_quality'] = 50

        # 2. æŠ€è¡“æ·±åº¦ (30åˆ†)
        # æª¢æŸ¥æ˜¯å¦æœ‰æ·±å…¥çš„æŠ€è¡“èªªæ˜
        technical_indicators = [
            r'åŸç†|æ©Ÿåˆ¶|æ¶æ§‹|è¨­è¨ˆæ¨¡å¼',
            r'å¯¦ä½œ|å¯¦ç¾|å¯¦æ–½',
            r'å„ªåŒ–|æ”¹é€²|æœ€ä½³å¯¦è¸',
            r'é™åˆ¶|æ³¨æ„äº‹é …|é™·é˜±',
            r'æ¯”è¼ƒ|å°æ¯”|å·®ç•°'
        ]

        depth_score = 0
        for indicator in technical_indicators:
            if re.search(indicator, content):
                depth_score += 6

        score += min(30, depth_score)
        details['technical_depth'] = min(100, depth_score * 3.3)

        # 3. ç†è«–èˆ‡å¯¦è¸å¹³è¡¡ (20åˆ†)
        # æª¢æŸ¥æ˜¯å¦æ—¢æœ‰ç†è«–èªªæ˜åˆæœ‰å¯¦éš›ç¯„ä¾‹
        theory_keywords = ['åŸç†', 'æ¦‚å¿µ', 'å®šç¾©', 'ç‚ºä»€éº¼', 'ç†è«–']
        practice_keywords = ['å¦‚ä½•', 'æ­¥é©Ÿ', 'ç¯„ä¾‹', 'å¯¦éš›', 'å…·é«”']

        has_theory = any(keyword in content for keyword in theory_keywords)
        has_practice = any(keyword in content for keyword in practice_keywords)

        if has_theory and has_practice:
            score += 20
            details['theory_practice_balance'] = True
        elif has_theory or has_practice:
            score += 10

        # 4. å°ˆæ¥­è¡“èª (20åˆ†)
        # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨ä¸¦è§£é‡‹å°ˆæ¥­è¡“èª
        # ç°¡åŒ–è™•ç†ï¼šæª¢æŸ¥æ˜¯å¦æœ‰è¡“èªä¸¦æä¾›èªªæ˜
        term_explanation_pattern = r'([A-Z]{2,}|[\u4e00-\u9fa5]{2,})\s*[ï¼ˆ(].*?[ï¼‰)]'
        explanations = re.findall(term_explanation_pattern, content)

        if len(explanations) >= 5:
            score += 20
            details['professional_terms'] = explanations[:3]
        elif len(explanations) >= 3:
            score += 15
            details['professional_terms'] = explanations[:2]
        elif len(explanations) >= 1:
            score += 10
            details['professional_terms'] = explanations[:1]

        return min(100, score), details

    def _analyze_authoritativeness(self, content: str) -> Tuple[float, Dict]:
        """
        åˆ†æã€Œæ¬Šå¨æ€§ã€ç¶­åº¦

        æª¢æŸ¥é …ç›®ï¼š
        - å¼•ç”¨å¯é ä¾†æº
        - æ•¸æ“šæ”¯æŒ
        - å¼•ç”¨æœ€æ–°è³‡è¨Š
        - ä½œè€…è³‡æ­·èªªæ˜
        """
        score = 0.0
        details = {
            'has_citations': False,
            'citation_count': 0,
            'has_data': False,
            'data_count': 0,
            'citations': [],
            'has_author_bio': False
        }

        # 1. å¼•ç”¨ä¾†æº (40åˆ†)
        # æª¢æŸ¥å¤–éƒ¨é€£çµå’Œå¼•ç”¨
        url_pattern = r'https?://[^\s\)ã€‘ã€]+'
        urls = re.findall(url_pattern, content)

        # æ¬Šå¨ä¾†æºåŸŸå
        authoritative_domains = [
            'github.com', 'docs.', 'arxiv.org', 'wikipedia.org',
            'stackoverflow.com', 'medium.com', 'dev.to',
            'anthropic.com', 'openai.com', 'google.com',
            '\.edu', '\.gov', '\.org'
        ]

        authoritative_count = sum(
            1 for url in urls
            if any(domain in url.lower() for domain in authoritative_domains)
        )

        details['citation_count'] = len(urls)
        details['citations'] = urls[:5]

        if authoritative_count >= 5:
            score += 40
            details['has_citations'] = True
        elif authoritative_count >= 3:
            score += 30
            details['has_citations'] = True
        elif authoritative_count >= 1:
            score += 20
            details['has_citations'] = True
        elif len(urls) >= 3:
            score += 15
            details['has_citations'] = True

        # 2. æ•¸æ“šæ”¯æŒ (30åˆ†)
        # æª¢æŸ¥çµ±è¨ˆæ•¸æ“šã€ç™¾åˆ†æ¯”ã€å…·é«”æ•¸å­—
        data_patterns = [
            r'\d+%',
            r'\d+å€',
            r'æ ¹æ“š.*èª¿æŸ¥|ç ”ç©¶|å ±å‘Š',
            r'æ•¸æ“šé¡¯ç¤º|çµ±è¨ˆ|æŒ‡å‡º'
        ]

        data_mentions = sum(len(re.findall(p, content)) for p in data_patterns)
        details['data_count'] = data_mentions

        if data_mentions >= 5:
            score += 30
            details['has_data'] = True
        elif data_mentions >= 3:
            score += 20
            details['has_data'] = True
        elif data_mentions >= 1:
            score += 10
            details['has_data'] = True

        # 3. æ™‚æ•ˆæ€§ (20åˆ†)
        # æª¢æŸ¥æ˜¯å¦æåˆ°æœ€æ–°å¹´ä»½ã€ç‰ˆæœ¬
        current_year = 2025
        recent_years = [str(year) for year in range(current_year - 2, current_year + 1)]

        has_recent_info = any(year in content for year in recent_years)

        version_pattern = r'v?\d+\.\d+(?:\.\d+)?'
        has_version = bool(re.search(version_pattern, content))

        if has_recent_info and has_version:
            score += 20
        elif has_recent_info or has_version:
            score += 10

        # 4. ä½œè€…è³‡æ­· (10åˆ†)
        # æª¢æŸ¥æ˜¯å¦æœ‰ã€Œé—œæ–¼ä½œè€…ã€æˆ–ä½œè€…ä»‹ç´¹
        author_patterns = [
            r'é—œæ–¼ä½œè€…|ä½œè€…ç°¡ä»‹|Author',
            r'æˆ‘æ˜¯.*å·¥ç¨‹å¸«|é–‹ç™¼è€…|å°ˆå®¶',
            r'\d+å¹´[ç¶“é©—|è³‡æ­·]'
        ]

        if any(re.search(p, content) for p in author_patterns):
            score += 10
            details['has_author_bio'] = True

        return min(100, score), details

    def _analyze_trustworthiness(self, content: str) -> Tuple[float, Dict]:
        """
        åˆ†æã€Œå¯ä¿¡åº¦ã€ç¶­åº¦

        æª¢æŸ¥é …ç›®ï¼š
        - è³‡è¨Šé€æ˜åº¦ï¼ˆèªªæ˜é™åˆ¶ã€ä¸ç¢ºå®šæ€§ï¼‰
        - é¿å…èª‡å¤§å®£ç¨±
        - æä¾›å¤šæ–¹è§€é»
        - æ›´æ–°æ—¥æœŸæ¨™è¨»
        """
        score = 0.0
        details = {
            'has_limitations': False,
            'avoids_exaggeration': True,
            'has_multiple_perspectives': False,
            'has_update_date': False,
            'warning_phrases': [],
            'exaggeration_phrases': []
        }

        # 1. é€æ˜åº¦ - èªªæ˜é™åˆ¶å’Œä¸ç¢ºå®šæ€§ (30åˆ†)
        limitation_patterns = [
            r'é™åˆ¶|ä¾·é™|ä¸è¶³',
            r'æ³¨æ„|å°å¿ƒ|è¬¹æ…',
            r'å¯èƒ½|ä¹Ÿè¨±|æˆ–è¨±',
            r'ä¸ä¸€å®š|æœªå¿…',
            r'éœ€è¦.*é©—è­‰|ç¢ºèª'
        ]

        limitation_count = sum(len(re.findall(p, content)) for p in limitation_patterns)
        details['warning_phrases'] = re.findall(limitation_patterns[1], content)[:3]

        if limitation_count >= 5:
            score += 30
            details['has_limitations'] = True
        elif limitation_count >= 3:
            score += 20
            details['has_limitations'] = True
        elif limitation_count >= 1:
            score += 10
            details['has_limitations'] = True

        # 2. é¿å…èª‡å¤§ (30åˆ†)
        exaggeration_patterns = [
            r'æœ€[å¥½|ä½³|å„ª|å¼·]',
            r'ç¬¬ä¸€|No\.?\s*1',
            r'100%|çµ•å°|ä¸€å®š',
            r'ä¿è­‰|å¿…å®š|è‚¯å®š',
            r'å®Œç¾|ç„¡æ•µ|ç¥ç´š'
        ]

        exaggeration_count = sum(len(re.findall(p, content)) for p in exaggeration_patterns)
        details['exaggeration_phrases'] = re.findall('|'.join(exaggeration_patterns), content)[:3]

        if exaggeration_count == 0:
            score += 30
        elif exaggeration_count <= 2:
            score += 20
            details['avoids_exaggeration'] = True
        elif exaggeration_count <= 5:
            score += 10
            details['avoids_exaggeration'] = False
        else:
            details['avoids_exaggeration'] = False

        # 3. å¤šæ–¹è§€é» (20åˆ†)
        perspective_patterns = [
            r'å¦ä¸€æ–¹é¢|ç„¶è€Œ|ä½†æ˜¯',
            r'æœ‰äººèªç‚º|éƒ¨åˆ†.*èªç‚º',
            r'å„ªé».*ç¼ºé»|å„ªå‹¢.*åŠ£å‹¢',
            r'æ”¯æŒè€…|åå°è€…'
        ]

        perspective_count = sum(len(re.findall(p, content)) for p in perspective_patterns)

        if perspective_count >= 3:
            score += 20
            details['has_multiple_perspectives'] = True
        elif perspective_count >= 1:
            score += 10
            details['has_multiple_perspectives'] = True

        # 4. æ›´æ–°æ—¥æœŸ (20åˆ†)
        date_patterns = [
            r'æ›´æ–°.*20\d{2}',
            r'æœ€å¾Œæ›´æ–°|Last Updated',
            r'20\d{2}[å¹´-]\d{1,2}[æœˆ-]\d{1,2}'
        ]

        if any(re.search(p, content) for p in date_patterns):
            score += 20
            details['has_update_date'] = True

        return min(100, score), details

    def _generate_insights(
        self,
        scores: EEATScore,
        exp_details: Dict,
        exp_details_2: Dict,
        auth_details: Dict,
        trust_details: Dict
    ) -> Tuple[List[str], List[str], List[str]]:
        """ç”Ÿæˆå„ªé»ã€ç¼ºé»å’Œå»ºè­°"""
        strengths = []
        weaknesses = []
        recommendations = []

        # åˆ†æç¶“é©— (Experience)
        if scores.experience >= 75:
            strengths.append(f"âœ… ç¶“é©—åˆ†æ•¸å„ªç§€ ({scores.experience}/100)ï¼šåŒ…å«è±å¯Œçš„ç¬¬ä¸€äººç¨±çœŸå¯¦ç¶“é©—")
        elif scores.experience < 50:
            weaknesses.append(f"âŒ ç¶“é©—åˆ†æ•¸åä½ ({scores.experience}/100)ï¼šç¼ºä¹çœŸå¯¦çš„å€‹äººç¶“é©—æ•˜è¿°")
            recommendations.append("ğŸ’¡ å¢åŠ ç¬¬ä¸€äººç¨±æ•˜è¿°ï¼Œåˆ†äº«çœŸå¯¦ä½¿ç”¨ç¶“é©—å’Œå…·é«”æƒ…å¢ƒ")

        if not exp_details['has_specific_details']:
            recommendations.append("ğŸ’¡ è£œå……å…·é«”ç´°ç¯€ï¼šæ™‚é–“åƒè€ƒã€æ•¸æ“šã€ä½¿ç”¨æƒ…å¢ƒ")

        # åˆ†æå°ˆæ¥­çŸ¥è­˜ (Expertise)
        if scores.expertise >= 75:
            strengths.append(f"âœ… å°ˆæ¥­çŸ¥è­˜åˆ†æ•¸å„ªç§€ ({scores.expertise}/100)ï¼šå±•ç¾æ·±åšçš„æŠ€è¡“ç†è§£")
        elif scores.expertise < 50:
            weaknesses.append(f"âŒ å°ˆæ¥­çŸ¥è­˜åˆ†æ•¸ä¸è¶³ ({scores.expertise}/100)ï¼šæŠ€è¡“æ·±åº¦æœ‰å¾…åŠ å¼·")
            recommendations.append("ğŸ’¡ å¢åŠ æŠ€è¡“æ·±åº¦ï¼šåŸç†èªªæ˜ã€æ¶æ§‹åˆ†æã€æœ€ä½³å¯¦è¸")

        if not exp_details_2['has_code_examples']:
            recommendations.append("ğŸ’¡ æ·»åŠ ç¨‹å¼ç¢¼ç¯„ä¾‹ä¸¦é™„ä¸Šè¨»è§£å’Œèªªæ˜")

        # åˆ†ææ¬Šå¨æ€§ (Authoritativeness)
        if scores.authoritativeness >= 75:
            strengths.append(f"âœ… æ¬Šå¨æ€§åˆ†æ•¸å„ªç§€ ({scores.authoritativeness}/100)ï¼šå……åˆ†å¼•ç”¨å¯é ä¾†æº")
        elif scores.authoritativeness < 50:
            weaknesses.append(f"âŒ æ¬Šå¨æ€§åˆ†æ•¸ä¸è¶³ ({scores.authoritativeness}/100)ï¼šç¼ºä¹æ¬Šå¨ä¾†æºæ”¯æŒ")
            recommendations.append("ğŸ’¡ å¼•ç”¨æ¬Šå¨ä¾†æºï¼šå®˜æ–¹æ–‡ä»¶ã€ç ”ç©¶å ±å‘Šã€çµ±è¨ˆæ•¸æ“š")

        if auth_details['citation_count'] < 3:
            recommendations.append("ğŸ’¡ å¢åŠ å¤–éƒ¨å¼•ç”¨é€£çµï¼ˆå»ºè­° 3-5 å€‹æ¬Šå¨ä¾†æºï¼‰")

        # åˆ†æå¯ä¿¡åº¦ (Trustworthiness)
        if scores.trustworthiness >= 75:
            strengths.append(f"âœ… å¯ä¿¡åº¦åˆ†æ•¸å„ªç§€ ({scores.trustworthiness}/100)ï¼šè³‡è¨Šé€æ˜ä¸”å®¢è§€")
        elif scores.trustworthiness < 50:
            weaknesses.append(f"âŒ å¯ä¿¡åº¦åˆ†æ•¸åä½ ({scores.trustworthiness}/100)ï¼šè³‡è¨Šé€æ˜åº¦ä¸è¶³")
            recommendations.append("ğŸ’¡ å¢åŠ é€æ˜åº¦ï¼šèªªæ˜é™åˆ¶ã€æ¨™è¨»ä¸ç¢ºå®šæ€§ã€é¿å…çµ•å°åŒ–è¡¨è¿°")

        if not trust_details['avoids_exaggeration']:
            recommendations.append("âš ï¸ é¿å…èª‡å¤§ç”¨è©ï¼šç§»é™¤ã€Œæœ€å¥½ã€ã€Œçµ•å°ã€ã€Œä¿è­‰ã€ç­‰è©å½™")

        if not trust_details['has_update_date']:
            recommendations.append("ğŸ’¡ æ·»åŠ æ›´æ–°æ—¥æœŸï¼Œè®“è®€è€…çŸ¥é“è³‡è¨Šæ™‚æ•ˆæ€§")

        # ç¸½åˆ†è©•ä¼°
        if scores.overall >= 85:
            strengths.append(f"ğŸ‰ E-E-A-T ç¸½åˆ†å„ªç§€ ({scores.overall}/100)ï¼šç¬¦åˆ Google é«˜å“è³ªå…§å®¹æ¨™æº–")
        elif scores.overall >= 70:
            strengths.append(f"ğŸ‘ E-E-A-T ç¸½åˆ†è‰¯å¥½ ({scores.overall}/100)ï¼šå…§å®¹å“è³ªé”æ¨™ï¼Œä»æœ‰æå‡ç©ºé–“")
        elif scores.overall < 55:
            weaknesses.append(f"âš ï¸ E-E-A-T ç¸½åˆ†éœ€æ”¹é€² ({scores.overall}/100)ï¼šå»ºè­°å„ªå…ˆæå‡ä½åˆ†é …ç›®")

        return strengths, weaknesses, recommendations

    def generate_report(self, result: EEATAnalysisResult, output_path: Optional[str] = None) -> str:
        """
        ç”Ÿæˆ Markdown æ ¼å¼çš„åˆ†æå ±å‘Š

        Args:
            result: åˆ†æçµæœ
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰

        Returns:
            Markdown æ ¼å¼çš„å ±å‘Šå…§å®¹
        """
        report_lines = []

        # æ¨™é¡Œ
        report_lines.append("# E-E-A-T å“è³ªåˆ†æå ±å‘Š")
        report_lines.append("")
        report_lines.append(f"**åˆ†ææ™‚é–“**: {result.analyzed_at}")
        report_lines.append(f"**ç³»çµ±ç‰ˆæœ¬**: v1.0.0")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # E-E-A-T èªªæ˜
        report_lines.append("## ğŸ“– é—œæ–¼ E-E-A-T")
        report_lines.append("")
        report_lines.append("E-E-A-T æ˜¯ Google è©•ä¼°å…§å®¹å“è³ªçš„æ ¸å¿ƒæ¨™æº–ï¼š")
        report_lines.append("")
        report_lines.append("- **Experience (ç¶“é©—)**: ä½œè€…æ˜¯å¦æœ‰ç¬¬ä¸€æ‰‹ç¶“é©—ï¼Ÿ")
        report_lines.append("- **Expertise (å°ˆæ¥­çŸ¥è­˜)**: å…§å®¹æ˜¯å¦å±•ç¾å°ˆæ¥­æ·±åº¦ï¼Ÿ")
        report_lines.append("- **Authoritativeness (æ¬Šå¨æ€§)**: ä½œè€…å’Œä¾†æºæ˜¯å¦å¯é ï¼Ÿ")
        report_lines.append("- **Trustworthiness (å¯ä¿¡åº¦)**: è³‡è¨Šæ˜¯å¦é€æ˜ä¸”èª å¯¦ï¼Ÿ")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # ç¸½åˆ†
        report_lines.append("## ğŸ“Š E-E-A-T ç¸½åˆ†")
        report_lines.append("")
        report_lines.append(f"### {result.scores.overall}/100")
        report_lines.append("")
        report_lines.append(self._get_progress_bar(result.scores.overall))
        report_lines.append("")
        report_lines.append(self._get_score_level(result.scores.overall))
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # å„é …åˆ†æ•¸
        report_lines.append("## ğŸ“ˆ å„é …åˆ†æ•¸æ˜ç´°")
        report_lines.append("")
        report_lines.append("| è©•ä¼°é …ç›® | åˆ†æ•¸ | é€²åº¦ | ç‹€æ…‹ |")
        report_lines.append("|---------|------|------|------|")

        items = [
            ("Experience (ç¶“é©—)", result.scores.experience),
            ("Expertise (å°ˆæ¥­çŸ¥è­˜)", result.scores.expertise),
            ("Authoritativeness (æ¬Šå¨æ€§)", result.scores.authoritativeness),
            ("Trustworthiness (å¯ä¿¡åº¦)", result.scores.trustworthiness)
        ]

        for name, score in items:
            bar = self._get_mini_progress_bar(score)
            status = self._get_score_emoji(score)
            report_lines.append(f"| {name} | {score}/100 | {bar} | {status} |")

        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # å„ªé»
        if result.strengths:
            report_lines.append("## âœ… å„ªé»")
            report_lines.append("")
            for strength in result.strengths:
                report_lines.append(f"- {strength}")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # ç¼ºé»
        if result.weaknesses:
            report_lines.append("## âš ï¸ éœ€è¦æ”¹é€²")
            report_lines.append("")
            for weakness in result.weaknesses:
                report_lines.append(f"- {weakness}")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # å»ºè­°
        if result.recommendations:
            report_lines.append("## ğŸ’¡ å„ªåŒ–å»ºè­°")
            report_lines.append("")
            for i, rec in enumerate(result.recommendations, 1):
                report_lines.append(f"{i}. {rec}")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # è©³ç´°åˆ†æ
        report_lines.append("## ğŸ” è©³ç´°åˆ†æ")
        report_lines.append("")

        # Experience è©³æƒ…
        report_lines.append(f"### Experience (ç¶“é©—) - {result.scores.experience}/100")
        report_lines.append("")
        exp_d = result.details['experience']
        report_lines.append(f"- ç¬¬ä¸€äººç¨±æ•˜è¿°: {'âœ… å……è¶³' if exp_d['has_first_person'] else 'âŒ ä¸è¶³'}")
        report_lines.append(f"- å…·é«”ç´°ç¯€: {'âœ… å……è¶³' if exp_d['has_specific_details'] else 'âŒ ä¸è¶³'}")
        report_lines.append(f"- å€‹äººè¦‹è§£: {'âœ… æœ‰' if exp_d['has_personal_insights'] else 'âŒ ç¼ºä¹'}")

        if exp_d['consistent_with_profile'] is not None:
            status = 'âœ… ä¸€è‡´' if exp_d['consistent_with_profile'] else 'âš ï¸ éœ€æª¢æŸ¥'
            report_lines.append(f"- èˆ‡ç¶“é©—æª”æ¡ˆä¸€è‡´æ€§: {status}")

        report_lines.append("")

        # Expertise è©³æƒ…
        report_lines.append(f"### Expertise (å°ˆæ¥­çŸ¥è­˜) - {result.scores.expertise}/100")
        report_lines.append("")
        exp_d2 = result.details['expertise']
        report_lines.append(f"- ç¨‹å¼ç¢¼ç¯„ä¾‹: {'âœ… æœ‰' if exp_d2['has_code_examples'] else 'âŒ ç„¡'}")
        report_lines.append(f"- ç¨‹å¼ç¢¼å“è³ª: {exp_d2['code_quality']}/100")
        report_lines.append(f"- æŠ€è¡“æ·±åº¦: {exp_d2['technical_depth']}/100")
        report_lines.append(f"- ç†è«–å¯¦è¸å¹³è¡¡: {'âœ… å¹³è¡¡' if exp_d2['theory_practice_balance'] else 'âš ï¸ å¤±è¡¡'}")
        report_lines.append("")

        # Authoritativeness è©³æƒ…
        report_lines.append(f"### Authoritativeness (æ¬Šå¨æ€§) - {result.scores.authoritativeness}/100")
        report_lines.append("")
        auth_d = result.details['authoritativeness']
        report_lines.append(f"- å¼•ç”¨ä¾†æº: {'âœ… æœ‰ (' + str(auth_d['citation_count']) + ' å€‹)' if auth_d['has_citations'] else 'âŒ ç„¡'}")
        report_lines.append(f"- æ•¸æ“šæ”¯æŒ: {'âœ… æœ‰ (' + str(auth_d['data_count']) + ' è™•)' if auth_d['has_data'] else 'âŒ ç„¡'}")
        report_lines.append(f"- ä½œè€…ç°¡ä»‹: {'âœ… æœ‰' if auth_d['has_author_bio'] else 'âš ï¸ å»ºè­°è£œå……'}")
        report_lines.append("")

        # Trustworthiness è©³æƒ…
        report_lines.append(f"### Trustworthiness (å¯ä¿¡åº¦) - {result.scores.trustworthiness}/100")
        report_lines.append("")
        trust_d = result.details['trustworthiness']
        report_lines.append(f"- èªªæ˜é™åˆ¶: {'âœ… æœ‰' if trust_d['has_limitations'] else 'âš ï¸ å»ºè­°è£œå……'}")
        report_lines.append(f"- é¿å…èª‡å¤§: {'âœ… è‰¯å¥½' if trust_d['avoids_exaggeration'] else 'âŒ æœ‰èª‡å¤§ç”¨è©'}")
        report_lines.append(f"- å¤šæ–¹è§€é»: {'âœ… æœ‰' if trust_d['has_multiple_perspectives'] else 'âš ï¸ å»ºè­°è£œå……'}")
        report_lines.append(f"- æ›´æ–°æ—¥æœŸ: {'âœ… æœ‰' if trust_d['has_update_date'] else 'âš ï¸ å»ºè­°æ·»åŠ '}")
        report_lines.append("")

        report_lines.append("---")
        report_lines.append("")

        # ç¸½çµå»ºè­°
        report_lines.append("## ğŸ“‹ è¡Œå‹•æ¸…å–®")
        report_lines.append("")
        report_lines.append("æ ¹æ“šåˆ†æçµæœï¼Œå»ºè­°å„ªå…ˆè™•ç†ï¼š")
        report_lines.append("")

        # æ‰¾å‡ºå¾—åˆ†æœ€ä½çš„é …ç›®
        scores_dict = {
            'Experience': result.scores.experience,
            'Expertise': result.scores.expertise,
            'Authoritativeness': result.scores.authoritativeness,
            'Trustworthiness': result.scores.trustworthiness
        }
        sorted_scores = sorted(scores_dict.items(), key=lambda x: x[1])

        for i, (name, score) in enumerate(sorted_scores[:2], 1):
            report_lines.append(f"{i}. **æå‡ {name}** (ç•¶å‰: {score}/100)")

        report_lines.append("")
        report_lines.append("å®Œæˆé€™äº›æ”¹é€²å¾Œï¼Œé æœŸ E-E-A-T ç¸½åˆ†å¯æå‡ 10-20 åˆ†ã€‚")
        report_lines.append("")

        # åº•éƒ¨è³‡è¨Š
        report_lines.append("---")
        report_lines.append("")
        report_lines.append("**å·¥å…·**: E-E-A-T åˆ†æå™¨ v1.0.0")
        report_lines.append("**ä½ç½®**: `.claude/skills/seo/eeat_analyzer.py`")
        report_lines.append("")

        report = "\n".join(report_lines)

        # å„²å­˜æª”æ¡ˆ
        if output_path:
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"âœ… å ±å‘Šå·²å„²å­˜è‡³: {output_path}")

        return report

    def _get_progress_bar(self, score: float, width: int = 40) -> str:
        """ç”Ÿæˆé€²åº¦æ¢"""
        filled = int(score / 100 * width)
        bar = 'â–ˆ' * filled + 'â–‘' * (width - filled)
        return f"```\n{bar} {score}%\n```"

    def _get_mini_progress_bar(self, score: float, width: int = 10) -> str:
        """ç”Ÿæˆå°å‹é€²åº¦æ¢"""
        filled = int(score / 100 * width)
        return 'â–ˆ' * filled + 'â–‘' * (width - filled)

    def _get_score_emoji(self, score: float) -> str:
        """æ ¹æ“šåˆ†æ•¸è¿”å›è¡¨æƒ…ç¬¦è™Ÿ"""
        if score >= 85:
            return "ğŸŒŸ å„ªç§€"
        elif score >= 70:
            return "âœ… è‰¯å¥½"
        elif score >= 55:
            return "âš ï¸ å°šå¯"
        else:
            return "âŒ éœ€æ”¹é€²"

    def _get_score_level(self, score: float) -> str:
        """æ ¹æ“šåˆ†æ•¸è¿”å›è©•ç´šæè¿°"""
        if score >= 85:
            return "**è©•ç´š**: ğŸŒŸ å„ªç§€ - ç¬¦åˆ Google é«˜å“è³ªå…§å®¹æ¨™æº–ï¼Œæœ‰æœ›ç²å¾—è¼ƒå¥½æ’å"
        elif score >= 70:
            return "**è©•ç´š**: âœ… è‰¯å¥½ - å…§å®¹å“è³ªé”æ¨™ï¼ŒæŒçºŒå„ªåŒ–å¯é€²ä¸€æ­¥æå‡"
        elif score >= 55:
            return "**è©•ç´š**: âš ï¸ å°šå¯ - åŸºæœ¬è¦ç´ å…·å‚™ï¼Œä½†éœ€è¦é¡¯è‘—æ”¹é€²"
        else:
            return "**è©•ç´š**: âŒ éœ€æ”¹é€² - E-E-A-T å“è³ªä¸è¶³ï¼Œå»ºè­°é‡æ–°æª¢è¦–å…§å®¹"


def main():
    """å‘½ä»¤åˆ—ä»‹é¢"""
    parser = argparse.ArgumentParser(
        description='E-E-A-T å…§å®¹å“è³ªåˆ†æå™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # åˆ†ææ–‡ç« ï¼ˆé¡¯ç¤ºæ–¼çµ‚ç«¯ï¼‰
  python eeat_analyzer.py --article draft_final.md

  # åˆ†æä¸¦ç”¢ç”Ÿå ±å‘Š
  python eeat_analyzer.py --article draft_final.md --output eeat_report.md

  # æä¾›ç¶“é©—æª”æ¡ˆä»¥ç²å¾—æ›´æº–ç¢ºçš„åˆ†æ
  python eeat_analyzer.py --article draft_final.md \\
      --experience experience_profile.md --output eeat_report.md

  # JSON æ ¼å¼è¼¸å‡º
  python eeat_analyzer.py --article draft_final.md --json
        """
    )

    parser.add_argument(
        '--article', '-a',
        required=True,
        help='è¦åˆ†æçš„æ–‡ç« æª”æ¡ˆè·¯å¾‘'
    )

    parser.add_argument(
        '--experience', '-e',
        help='ç”¨æˆ¶ç¶“é©—æª”æ¡ˆè·¯å¾‘ (experience_profile.md)'
    )

    parser.add_argument(
        '--output', '-o',
        help='è¼¸å‡ºå ±å‘Šæª”æ¡ˆè·¯å¾‘'
    )

    parser.add_argument(
        '--config', '-c',
        help='é…ç½®æª”æ¡ˆè·¯å¾‘'
    )

    parser.add_argument(
        '--json',
        action='store_true',
        help='ä»¥ JSON æ ¼å¼è¼¸å‡ºçµæœ'
    )

    args = parser.parse_args()

    # è®€å–æ–‡ç« 
    try:
        with open(args.article, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ–‡ç« æª”æ¡ˆ {args.article}")
        return 1

    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = EEATAnalyzer(config_path=args.config)

    # åŸ·è¡Œåˆ†æ
    result = analyzer.analyze(content, experience_profile_path=args.experience)

    # è¼¸å‡ºçµæœ
    if args.json:
        # JSON æ ¼å¼
        output_data = {
            'scores': result.scores.to_dict(),
            'strengths': result.strengths,
            'weaknesses': result.weaknesses,
            'recommendations': result.recommendations,
            'analyzed_at': result.analyzed_at
        }
        print(json.dumps(output_data, ensure_ascii=False, indent=2))
    else:
        # Markdown å ±å‘Š
        report = analyzer.generate_report(result, output_path=args.output)
        if not args.output:
            print(report)

    return 0


if __name__ == '__main__':
    exit(main())
