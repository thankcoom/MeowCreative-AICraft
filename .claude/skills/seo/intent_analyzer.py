#!/usr/bin/env python3
"""
SEO æœå°‹æ„åœ–åˆ†æå™¨
åˆ†æé—œéµå­—çš„æœå°‹æ„åœ–ï¼Œä¸¦æä¾›çµæ§‹åŒ–å»ºè­°

ç‰ˆæœ¬: 1.0.0
å»ºç«‹æ—¥æœŸ: 2025-10-24
"""

import re
import yaml
import json
from enum import Enum
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime


class SearchIntent(Enum):
    """æœå°‹æ„åœ–é¡å‹"""
    TUTORIAL = "æ•™å­¸å‹"           # å¦‚ä½•åšXã€æ­¥é©Ÿã€æŒ‡å—
    INFORMATIONAL = "è³‡è¨Šå‹"      # ä»€éº¼æ˜¯Xã€ä»‹ç´¹ã€èªªæ˜
    COMPARISON = "æ¯”è¼ƒå‹"         # X vs Yã€å·®ç•°ã€å“ªå€‹å¥½
    REVIEW = "è©•åƒ¹å‹"             # Xå¥½ç”¨å—ã€è©•æ¸¬ã€æ¨è–¦
    TRANSACTIONAL = "äº¤æ˜“å‹"      # è³¼è²·Xã€åƒ¹æ ¼ã€è²»ç”¨
    PROBLEM_SOLVING = "å•é¡Œè§£æ±ºå‹" # å¦‚ä½•è§£æ±ºã€éŒ¯èª¤ä¿®å¾©ã€ç–‘é›£æ’è§£


class IntentAnalyzer:
    """æœå°‹æ„åœ–åˆ†æå™¨"""

    def __init__(self, rules_path: str = ".claude/skills/seo/intent_rules.yaml"):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            rules_path: æ„åœ–è¦å‰‡é…ç½®æª”è·¯å¾‘
        """
        self.rules_path = Path(rules_path)
        self.rules = self._load_rules()

    def _load_rules(self) -> Dict[str, Any]:
        """è¼‰å…¥æ„åœ–åŒ¹é…è¦å‰‡"""
        if not self.rules_path.exists():
            # å¦‚æœè¦å‰‡æª”ä¸å­˜åœ¨ï¼Œä½¿ç”¨å…§å»ºè¦å‰‡
            return self._get_default_rules()

        try:
            with open(self.rules_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except (yaml.YAMLError, IOError) as e:
            print(f"âš ï¸  è¼‰å…¥è¦å‰‡æª”å¤±æ•—: {e}")
            return self._get_default_rules()

    def _get_default_rules(self) -> Dict[str, Any]:
        """å–å¾—é è¨­çš„æ„åœ–åŒ¹é…è¦å‰‡"""
        return {
            'intent_patterns': {
                'tutorial': {
                    'keywords': ['å¦‚ä½•', 'æ€éº¼', 'æ•™å­¸', 'æ­¥é©Ÿ', 'æŒ‡å—', 'æ–¹æ³•', 'æ‰‹æŠŠæ‰‹', 'å®Œæ•´', 'å¯¦ä½œ'],
                    'weight': 1.0
                },
                'informational': {
                    'keywords': ['æ˜¯ä»€éº¼', 'ä»‹ç´¹', 'èªªæ˜', 'åŸç†', 'ç‚ºä»€éº¼', 'å®šç¾©', 'æ¦‚å¿µ', 'è§£æ'],
                    'weight': 0.9
                },
                'comparison': {
                    'keywords': ['æ¯”è¼ƒ', 'vs', 'å·®ç•°', 'å“ªå€‹å¥½', 'æ¨è–¦', 'é¸æ“‡', 'å°æ¯”'],
                    'weight': 1.0
                },
                'review': {
                    'keywords': ['å¥½ç”¨å—', 'è©•æ¸¬', 'è©•åƒ¹', 'å¿ƒå¾—', 'å„ªç¼ºé»', 'å€¼å¾—'],
                    'weight': 0.8
                },
                'problem_solving': {
                    'keywords': ['è§£æ±º', 'ä¿®å¾©', 'éŒ¯èª¤', 'å•é¡Œ', 'ç„¡æ³•', 'å¤±æ•—', 'ä¸èƒ½', 'ç–‘é›£'],
                    'weight': 1.0
                }
            }
        }

    def analyze(self, keyword: str, article_content: Optional[str] = None) -> Dict[str, Any]:
        """
        åˆ†æé—œéµå­—çš„æœå°‹æ„åœ–

        Args:
            keyword: ä¸»è¦é—œéµå­—
            article_content: æ–‡ç« å…§å®¹ï¼ˆå¯é¸ï¼Œç”¨æ–¼åŒ¹é…åº¦åˆ†æï¼‰

        Returns:
            Dict: åˆ†æçµæœ
        """
        # æ¨™æº–åŒ–é—œéµå­—
        normalized_keyword = keyword.lower().strip()

        # è¨ˆç®—å„æ„åœ–çš„åŒ¹é…åˆ†æ•¸
        intent_scores = {}
        patterns = self.rules.get('intent_patterns', {})

        for intent_type, config in patterns.items():
            keywords = config.get('keywords', [])
            weight = config.get('weight', 1.0)

            # è¨ˆç®—åŒ¹é…æ•¸é‡
            matches = sum(1 for kw in keywords if kw in normalized_keyword)
            score = matches * weight

            if score > 0:
                intent_scores[intent_type] = score

        # ç¢ºå®šä¸»è¦æ„åœ–
        if not intent_scores:
            # å¦‚æœæ²’æœ‰åŒ¹é…ï¼Œé è¨­ç‚ºè³‡è¨Šå‹
            primary_intent = 'informational'
            confidence = 0.5
        else:
            # é¸æ“‡åˆ†æ•¸æœ€é«˜çš„æ„åœ–
            primary_intent = max(intent_scores, key=intent_scores.get)
            max_score = intent_scores[primary_intent]
            total_score = sum(intent_scores.values())
            confidence = max_score / total_score if total_score > 0 else 0.5

        # å–å¾—æ„åœ–å°æ‡‰çš„å»ºè­°
        recommendations = self._get_recommendations(primary_intent)

        # å¦‚æœæœ‰æ–‡ç« å…§å®¹ï¼Œé€²è¡ŒåŒ¹é…åº¦åˆ†æ
        match_score = None
        match_details = None
        if article_content:
            match_score, match_details = self._analyze_content_match(
                article_content,
                primary_intent,
                recommendations
            )

        return {
            'keyword': keyword,
            'primary_intent': primary_intent,
            'intent_label': self._get_intent_label(primary_intent),
            'confidence': round(confidence, 2),
            'all_scores': intent_scores,
            'recommendations': recommendations,
            'match_score': match_score,
            'match_details': match_details,
            'analyzed_at': datetime.now().isoformat()
        }

    def _get_intent_label(self, intent_type: str) -> str:
        """å–å¾—æ„åœ–çš„ä¸­æ–‡æ¨™ç±¤"""
        labels = {
            'tutorial': SearchIntent.TUTORIAL.value,
            'informational': SearchIntent.INFORMATIONAL.value,
            'comparison': SearchIntent.COMPARISON.value,
            'review': SearchIntent.REVIEW.value,
            'transactional': SearchIntent.TRANSACTIONAL.value,
            'problem_solving': SearchIntent.PROBLEM_SOLVING.value
        }
        return labels.get(intent_type, 'æœªçŸ¥')

    def _get_recommendations(self, intent_type: str) -> Dict[str, Any]:
        """æ ¹æ“šæ„åœ–é¡å‹å–å¾—çµæ§‹åŒ–å»ºè­°"""
        recommendations = {
            'tutorial': {
                'title_format': 'ã€å®Œæ•´æŒ‡å—ã€‘å¦‚ä½•{action} - {benefit}',
                'title_examples': [
                    'ã€å®Œæ•´æŒ‡å—ã€‘å¦‚ä½•ä½¿ç”¨ Claude Code å»ºç«‹ AI Agent - 10åˆ†é˜å¿«é€Ÿä¸Šæ‰‹',
                    'æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨ Python æ‰“é€ é‡åŒ–äº¤æ˜“ç³»çµ± - å¾é›¶åˆ°å¯¦æˆ°'
                ],
                'must_include': [
                    'å‰ç½®æº–å‚™æ¸…å–®ï¼ˆç’°å¢ƒã€å·¥å…·ã€çŸ¥è­˜è¦æ±‚ï¼‰',
                    'é€æ­¥æ“ä½œæ­¥é©Ÿï¼ˆå¸¶ç·¨è™Ÿã€å¸¶æˆªåœ–ï¼‰',
                    'æ¯å€‹æ­¥é©Ÿçš„é æœŸçµæœ',
                    'å¸¸è¦‹éŒ¯èª¤å’Œè§£æ±ºæ–¹æ³•',
                    'é€²éšæŠ€å·§å’Œæœ€ä½³å¯¦è¸',
                    'å®Œæ•´çš„å¯åŸ·è¡Œç¯„ä¾‹'
                ],
                'structure_template': [
                    '## å¼•è¨€ï¼ˆç‚ºä»€éº¼éœ€è¦å­¸é€™å€‹ï¼‰',
                    '## å‰ç½®æº–å‚™',
                    '## æ­¥é©Ÿä¸€ï¼š...',
                    '## æ­¥é©ŸäºŒï¼š...',
                    '## å¸¸è¦‹å•é¡Œ',
                    '## é€²éšæŠ€å·§',
                    '## ç¸½çµèˆ‡ä¸‹ä¸€æ­¥'
                ],
                'tone': 'å‹å–„æŒ‡å°ã€å¾ªåºæ¼¸é€²ã€é¼“å‹µæ€§',
                'cta': 'ç«‹å³å˜—è©¦ã€ä¸‹è¼‰ç¯„ä¾‹ã€åŠ å…¥ç¤¾ç¾¤'
            },
            'informational': {
                'title_format': '{topic}å®Œå…¨è§£æ - {unique_angle}',
                'title_examples': [
                    'Claude Code å®Œå…¨è§£æ - 5å€‹ä½ ä¸çŸ¥é“çš„å¼·å¤§åŠŸèƒ½',
                    'AI Agent ç³»çµ±æ¶æ§‹æ·±åº¦å‰–æ - å¾åŸç†åˆ°å¯¦è¸'
                ],
                'must_include': [
                    'æ¸…æ™°çš„å®šç¾©ï¼ˆWhatï¼‰',
                    'å·¥ä½œåŸç†ï¼ˆHowï¼‰',
                    'ç‚ºä»€éº¼é‡è¦ï¼ˆWhyï¼‰',
                    'å¯¦éš›æ‡‰ç”¨å ´æ™¯',
                    'å„ªç¼ºé»åˆ†æ',
                    'èˆ‡ç›¸é—œæ¦‚å¿µçš„æ¯”è¼ƒ'
                ],
                'structure_template': [
                    '## å¼•è¨€ï¼ˆèƒŒæ™¯å’Œé‡è¦æ€§ï¼‰',
                    '## å®šç¾©å’Œæ ¸å¿ƒæ¦‚å¿µ',
                    '## å·¥ä½œåŸç†',
                    '## å¯¦éš›æ‡‰ç”¨å ´æ™¯',
                    '## å„ªç¼ºé»åˆ†æ',
                    '## ç¸½çµ'
                ],
                'tone': 'å°ˆæ¥­å®¢è§€ã€æ·±å…¥æ·ºå‡ºã€çµæ§‹æ¸…æ™°',
                'cta': 'æ·±å…¥é–±è®€ã€è¨‚é–±æ›´æ–°ã€ç›¸é—œæ–‡ç« '
            },
            'comparison': {
                'title_format': '{option1} vs {option2}ï¼š{decision_guide}',
                'title_examples': [
                    'Claude Code vs GitHub Copilotï¼š2025 AI ç·¨ç¨‹å·¥å…·é¸æ“‡æŒ‡å—',
                    'Python vs JavaScript é‡åŒ–äº¤æ˜“ï¼šå“ªå€‹æ›´é©åˆä½ ï¼Ÿ'
                ],
                'must_include': [
                    'å°æ¯”è¡¨æ ¼ï¼ˆåŠŸèƒ½ã€åƒ¹æ ¼ã€å„ªç¼ºé»ï¼‰',
                    'å„è‡ªçš„å„ªå‹¢å ´æ™¯',
                    'é©åˆçš„ç”¨æˆ¶é¡å‹',
                    'æ•ˆèƒ½/åƒ¹æ ¼æ¯”è¼ƒ',
                    'æ±ºç­–æ¡†æ¶æˆ–æµç¨‹åœ–',
                    'å¯¦éš›æ¸¬è©¦æ•¸æ“š'
                ],
                'structure_template': [
                    '## å¼•è¨€ï¼ˆç‚ºä»€éº¼éœ€è¦æ¯”è¼ƒï¼‰',
                    '## å¿«é€Ÿå°æ¯”è¡¨',
                    '## {Option1} æ·±åº¦åˆ†æ',
                    '## {Option2} æ·±åº¦åˆ†æ',
                    '## ä½¿ç”¨å ´æ™¯å»ºè­°',
                    '## æ±ºç­–æŒ‡å—',
                    '## ç¸½çµå»ºè­°'
                ],
                'tone': 'å®¢è§€ä¸­ç«‹ã€æ•¸æ“šé©…å‹•ã€å¯¦ç”¨å°å‘',
                'cta': 'é–‹å§‹è©¦ç”¨ã€æŸ¥çœ‹å®šåƒ¹ã€è«®è©¢å»ºè­°'
            },
            'review': {
                'title_format': '{product}æ·±åº¦è©•æ¸¬ - {time_period}ä½¿ç”¨å¿ƒå¾—',
                'title_examples': [
                    'Claude Code æ·±åº¦è©•æ¸¬ - 30å¤©å¯¦æˆ°ä½¿ç”¨å¿ƒå¾—',
                    'FinMind API é‡åŒ–äº¤æ˜“è©•åƒ¹ - å€¼å¾—æŠ•è³‡å—ï¼Ÿ'
                ],
                'must_include': [
                    'è©•æ¸¬ç’°å¢ƒå’ŒèƒŒæ™¯',
                    'å„ªé»åˆ—è¡¨ï¼ˆå…·é«”æ¡ˆä¾‹ï¼‰',
                    'ç¼ºé»åˆ—è¡¨ï¼ˆçœŸå¯¦å•é¡Œï¼‰',
                    'å¯¦éš›ä½¿ç”¨æ•¸æ“šæˆ–æˆªåœ–',
                    'èˆ‡é æœŸçš„å·®ç•°',
                    'æ˜¯å¦æ¨è–¦ï¼ˆæ˜ç¢ºçµè«–ï¼‰'
                ],
                'structure_template': [
                    '## è©•æ¸¬èƒŒæ™¯',
                    '## æ ¸å¿ƒå„ªå‹¢',
                    '## ä¸»è¦ç¼ºé»',
                    '## å¯¦æ¸¬æ•¸æ“š',
                    '## é©åˆå°è±¡',
                    '## æœ€çµ‚è©•åˆ†',
                    '## æ˜¯å¦æ¨è–¦'
                ],
                'tone': 'çœŸèª å¦ç‡ã€æœ‰ä¾æ“šã€å¹³è¡¡è§€é»',
                'cta': 'æŸ¥çœ‹å®˜ç¶²ã€å…è²»è©¦ç”¨ã€é–±è®€æ›´å¤šè©•æ¸¬'
            },
            'problem_solving': {
                'title_format': 'è§£æ±º{problem} - {solution_count}ç¨®æœ‰æ•ˆæ–¹æ³•',
                'title_examples': [
                    'è§£æ±º Claude Code ç„¡æ³•é€£æ¥å•é¡Œ - 5ç¨®è¨ºæ–·æ–¹æ³•',
                    'ä¿®å¾©é‡åŒ–å›æ¸¬éŒ¯èª¤ - å®Œæ•´æ’æŸ¥æŒ‡å—'
                ],
                'must_include': [
                    'å•é¡Œç—‡ç‹€æè¿°',
                    'å¯èƒ½çš„åŸå› åˆ†æ',
                    'è§£æ±ºæ–¹æ¡ˆï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰',
                    'æ¯å€‹æ–¹æ¡ˆçš„é©ç”¨æƒ…æ³',
                    'é é˜²æªæ–½',
                    'ä½•æ™‚éœ€è¦å°‹æ±‚å°ˆæ¥­å”åŠ©'
                ],
                'structure_template': [
                    '## å•é¡Œæè¿°',
                    '## åŸå› åˆ†æ',
                    '## è§£æ±ºæ–¹æ¡ˆä¸€ï¼ˆæœ€å¸¸è¦‹ï¼‰',
                    '## è§£æ±ºæ–¹æ¡ˆäºŒ',
                    '## è§£æ±ºæ–¹æ¡ˆä¸‰',
                    '## é é˜²æªæ–½',
                    '## ç¸½çµ'
                ],
                'tone': 'è§£æ±ºå°å‘ã€å‹™å¯¦é«˜æ•ˆã€åŒç†å¿ƒ',
                'cta': 'å˜—è©¦è§£æ±ºã€æ±‚åŠ©ç¤¾ç¾¤ã€è¯ç¹«æ”¯æ´'
            }
        }

        return recommendations.get(intent_type, recommendations['informational'])

    def _analyze_content_match(
        self,
        content: str,
        intent_type: str,
        recommendations: Dict[str, Any]
    ) -> tuple[float, Dict[str, Any]]:
        """
        åˆ†ææ–‡ç« å…§å®¹èˆ‡æ„åœ–çš„åŒ¹é…åº¦

        Args:
            content: æ–‡ç« å…§å®¹
            intent_type: æ„åœ–é¡å‹
            recommendations: æ„åœ–å»ºè­°

        Returns:
            tuple: (åŒ¹é…åˆ†æ•¸, åŒ¹é…è©³æƒ…)
        """
        must_include = recommendations.get('must_include', [])

        # æª¢æŸ¥å¿…è¦å…ƒç´ 
        matches = []
        misses = []

        # ç°¡åŒ–çš„é—œéµå­—åŒ¹é…é‚è¼¯
        keyword_mapping = {
            'å‰ç½®æº–å‚™': ['å‰ç½®', 'æº–å‚™', 'ç’°å¢ƒ', 'å®‰è£', 'è¦æ±‚'],
            'æ­¥é©Ÿ': ['æ­¥é©Ÿ', 'step', 'ç¬¬ä¸€', 'ç¬¬äºŒ', 'é¦–å…ˆ', 'æ¥è‘—'],
            'å¸¸è¦‹éŒ¯èª¤': ['éŒ¯èª¤', 'å•é¡Œ', 'æ³¨æ„', 'é¿å…'],
            'å®šç¾©': ['å®šç¾©', 'æ˜¯ä»€éº¼', 'æŒ‡çš„æ˜¯', 'æ„æ€'],
            'åŸç†': ['åŸç†', 'é‹ä½œ', 'å¦‚ä½•å·¥ä½œ', 'æ©Ÿåˆ¶'],
            'å„ªç¼ºé»': ['å„ªé»', 'ç¼ºé»', 'å¥½è™•', 'é™åˆ¶', 'å„ªå‹¢', 'åŠ£å‹¢'],
            'å°æ¯”': ['æ¯”è¼ƒ', 'å°æ¯”', 'vs', 'å·®ç•°'],
            'è¡¨æ ¼': ['|', 'è¡¨æ ¼'],
        }

        content_lower = content.lower()

        for item in must_include:
            item_lower = item.lower()
            found = False

            # æª¢æŸ¥é …ç›®ä¸­çš„é—œéµå­—
            for key, keywords in keyword_mapping.items():
                if key in item:
                    if any(kw in content_lower for kw in keywords):
                        matches.append(item)
                        found = True
                        break

            if not found:
                # ç›´æ¥æª¢æŸ¥é …ç›®æ–‡å­—
                if any(word in content_lower for word in item_lower.split()):
                    matches.append(item)
                else:
                    misses.append(item)

        # è¨ˆç®—åŒ¹é…åˆ†æ•¸
        total = len(must_include)
        matched = len(matches)
        match_score = matched / total if total > 0 else 1.0

        match_details = {
            'total_requirements': total,
            'matched': matched,
            'missing': len(misses),
            'matched_items': matches,
            'missing_items': misses
        }

        return round(match_score, 2), match_details

    def generate_report(
        self,
        analysis_result: Dict[str, Any],
        output_path: Optional[str] = None
    ) -> str:
        """
        ç”Ÿæˆ Markdown æ ¼å¼çš„åˆ†æå ±å‘Š

        Args:
            analysis_result: åˆ†æçµæœ
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰

        Returns:
            str: Markdown å ±å‘Šå…§å®¹
        """
        report = []

        # æ¨™é¡Œ
        report.append("# SEO æœå°‹æ„åœ–åˆ†æå ±å‘Š\n")
        report.append(f"**åˆ†ææ™‚é–“**: {analysis_result['analyzed_at']}\n")
        report.append("---\n")

        # é—œéµå­—å’Œæ„åœ–
        report.append("## ğŸ¯ ä¸»è¦é—œéµå­—\n")
        report.append(f"**é—œéµå­—**: {analysis_result['keyword']}\n")

        report.append("\n## ğŸ“Š æ„åœ–åˆ†é¡\n")
        report.append(f"- **ä¸»è¦æ„åœ–**: {analysis_result['intent_label']} ({analysis_result['primary_intent']})\n")
        report.append(f"- **ä¿¡å¿ƒåº¦**: {analysis_result['confidence'] * 100:.0f}%\n")

        # å…¶ä»–å¯èƒ½çš„æ„åœ–
        if analysis_result.get('all_scores'):
            report.append("\n**å…¶ä»–å¯èƒ½æ„åœ–**:\n")
            for intent, score in sorted(
                analysis_result['all_scores'].items(),
                key=lambda x: x[1],
                reverse=True
            ):
                if intent != analysis_result['primary_intent']:
                    report.append(f"- {self._get_intent_label(intent)}: {score}\n")

        # æ¨è–¦çµæ§‹
        rec = analysis_result.get('recommendations', {})

        report.append("\n## ğŸ’¡ æ¨è–¦æ–‡ç« çµæ§‹\n")
        report.append(f"### æ¨™é¡Œæ ¼å¼\n")
        report.append(f"```\n{rec.get('title_format', 'N/A')}\n```\n")

        report.append("\n**ç¯„ä¾‹æ¨™é¡Œ**:\n")
        for example in rec.get('title_examples', []):
            report.append(f"- {example}\n")

        report.append("\n### å¿…é ˆåŒ…å«çš„å…ƒç´ \n")
        for item in rec.get('must_include', []):
            report.append(f"- {item}\n")

        report.append("\n### å»ºè­°çµæ§‹\n")
        report.append("```markdown\n")
        for section in rec.get('structure_template', []):
            report.append(f"{section}\n")
        report.append("```\n")

        report.append("\n### èªæ°£é¢¨æ ¼\n")
        report.append(f"- **å»ºè­°èªæ°£**: {rec.get('tone', 'N/A')}\n")
        report.append(f"- **è¡Œå‹•å‘¼ç±² (CTA)**: {rec.get('cta', 'N/A')}\n")

        # å¦‚æœæœ‰åŒ¹é…åº¦åˆ†æ
        if analysis_result.get('match_score') is not None:
            match_score = analysis_result['match_score']
            match_details = analysis_result['match_details']

            report.append("\n## ğŸ“ˆ ç•¶å‰æ–‡ç« åŒ¹é…åº¦\n")
            report.append(f"**åŒ¹é…åˆ†æ•¸**: {match_score:.2f} / 1.0\n")

            # ç”¨é€²åº¦æ¢è¡¨ç¤º
            progress = int(match_score * 20)
            bar = "â–ˆ" * progress + "â–‘" * (20 - progress)
            report.append(f"```\n{bar} {match_score * 100:.0f}%\n```\n")

            report.append(f"\n### åŒ¹é…è©³æƒ…\n")
            report.append(f"- å¿…è¦å…ƒç´ ç¸½æ•¸: {match_details['total_requirements']}\n")
            report.append(f"- å·²åŒ…å«: {match_details['matched']}\n")
            report.append(f"- ç¼ºå°‘: {match_details['missing']}\n")

            if match_details.get('matched_items'):
                report.append("\nâœ… **å·²åŒ…å«çš„å…ƒç´ **:\n")
                for item in match_details['matched_items']:
                    report.append(f"- {item}\n")

            if match_details.get('missing_items'):
                report.append("\nâš ï¸ **ç¼ºå°‘çš„å…ƒç´ **:\n")
                for item in match_details['missing_items']:
                    report.append(f"- {item}\n")

            # å„ªåŒ–å»ºè­°
            report.append("\n## ğŸ”§ å„ªåŒ–å»ºè­°\n")
            if match_score >= 0.9:
                report.append("âœ… **æ–‡ç« çµæ§‹éå¸¸ç¬¦åˆæœå°‹æ„åœ–ï¼**\n")
                report.append("- ç¶­æŒç•¶å‰çµæ§‹\n")
                report.append("- ç¢ºä¿å…§å®¹æ·±åº¦å’Œå“è³ª\n")
            elif match_score >= 0.7:
                report.append("âš ï¸ **æ–‡ç« åŸºæœ¬ç¬¦åˆæœå°‹æ„åœ–ï¼Œä½†æœ‰æ”¹é€²ç©ºé–“**\n")
                report.append("\nå»ºè­°è£œå……:\n")
                for item in match_details.get('missing_items', [])[:3]:
                    report.append(f"1. å¢åŠ ã€Œ{item}ã€ç›¸é—œå…§å®¹\n")
            else:
                report.append("âŒ **æ–‡ç« çµæ§‹èˆ‡æœå°‹æ„åœ–å·®ç•°è¼ƒå¤§**\n")
                report.append("\nå¼·çƒˆå»ºè­°:\n")
                report.append(f"1. æŒ‰ç…§ã€Œ{rec.get('title_format', '')}ã€æ ¼å¼èª¿æ•´æ¨™é¡Œ\n")
                report.append(f"2. é‡æ–°çµ„ç¹”æ–‡ç« çµæ§‹ï¼Œåƒè€ƒä¸Šè¿°å»ºè­°çµæ§‹\n")
                report.append(f"3. è£œå……ç¼ºå°‘çš„å¿…è¦å…ƒç´ ï¼ˆç‰¹åˆ¥æ˜¯å‰ {min(3, len(match_details.get('missing_items', [])))} é …ï¼‰\n")

        # åƒè€ƒè³‡æ–™
        report.append("\n## ğŸ“š åƒè€ƒè³‡æ–™\n")
        report.append("- [Google æœå°‹æ„åœ–æŒ‡å—](https://developers.google.com/search/docs/fundamentals/creating-helpful-content)\n")
        report.append("- SEO æ„åœ–åŒ¹é…æœ€ä½³å¯¦è¸\n")

        report_content = "".join(report)

        # å¦‚æœæŒ‡å®šè¼¸å‡ºè·¯å¾‘ï¼Œå„²å­˜æª”æ¡ˆ
        if output_path:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)

            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_content)

            print(f"âœ… å ±å‘Šå·²å„²å­˜è‡³: {output_file}")

        return report_content


def main():
    """å‘½ä»¤è¡Œä½¿ç”¨ä»‹é¢"""
    import sys
    import argparse

    parser = argparse.ArgumentParser(
        description='SEO æœå°‹æ„åœ–åˆ†æå™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # åˆ†æé—œéµå­—
  python intent_analyzer.py analyze "å¦‚ä½•ä½¿ç”¨ Claude Code"

  # åˆ†æä¸¦ç”¢ç”Ÿå ±å‘Š
  python intent_analyzer.py analyze "Claude Code æ•™å­¸" --output output/intent_analysis.md

  # åˆ†æé—œéµå­—ä¸¦æ¯”å°æ–‡ç« 
  python intent_analyzer.py analyze "AI Agent é–‹ç™¼" --article output/session_xxx/final_article.md
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨æŒ‡ä»¤')

    # analyze å­å‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='åˆ†æé—œéµå­—çš„æœå°‹æ„åœ–')
    analyze_parser.add_argument('keyword', help='è¦åˆ†æçš„é—œéµå­—')
    analyze_parser.add_argument('--article', '-a', help='æ–‡ç« æª”æ¡ˆè·¯å¾‘ï¼ˆç”¨æ–¼åŒ¹é…åº¦åˆ†æï¼‰')
    analyze_parser.add_argument('--output', '-o', help='å ±å‘Šè¼¸å‡ºè·¯å¾‘')
    analyze_parser.add_argument('--json', action='store_true', help='ä»¥ JSON æ ¼å¼è¼¸å‡º')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    if args.command == 'analyze':
        analyzer = IntentAnalyzer()

        # è®€å–æ–‡ç« å…§å®¹ï¼ˆå¦‚æœæä¾›ï¼‰
        article_content = None
        if args.article:
            article_path = Path(args.article)
            if article_path.exists():
                with open(article_path, 'r', encoding='utf-8') as f:
                    article_content = f.read()
                print(f"ğŸ“„ å·²è¼‰å…¥æ–‡ç« : {args.article}\n")
            else:
                print(f"âš ï¸  æ‰¾ä¸åˆ°æ–‡ç« æª”æ¡ˆ: {args.article}\n")

        # åŸ·è¡Œåˆ†æ
        print(f"ğŸ” åˆ†æé—œéµå­—: {args.keyword}\n")
        result = analyzer.analyze(args.keyword, article_content)

        if args.json:
            # JSON è¼¸å‡º
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            # Markdown å ±å‘Š
            report = analyzer.generate_report(result, args.output)

            if not args.output:
                print(report)


if __name__ == "__main__":
    main()
