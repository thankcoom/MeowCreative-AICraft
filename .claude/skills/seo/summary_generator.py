#!/usr/bin/env python3
"""
AI Overviews Summary Generator
ç‚º Google AI Overviews ç”Ÿæˆå„ªåŒ–çš„æ‘˜è¦æ¡†

Google AI Overviews åœ¨ 2025 å¹´ 9 æœˆå·²è¦†è“‹ 30% çš„ç¾åœ‹æ¡Œé¢æŸ¥è©¢
é—œéµå„ªåŒ–è¦ç´ ï¼š
- 50-70 å­—çš„ç°¡æ½”æ‘˜è¦
- ç›´æ¥å›ç­”ç›®æ¨™å•é¡Œ
- ç°¡å–®æ˜“æ‡‚çš„èªè¨€
- å¿«é€Ÿåˆ‡å…¥é‡é»

Version: 1.0.0
Date: 2025-11-04
"""

import re
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass


@dataclass
class SummaryBox:
    """æ‘˜è¦æ¡†æ•¸æ“šçµæ§‹"""
    title: str  # å•é¡Œæˆ–ä¸»é¡Œ
    summary: str  # 50-70 å­—æ‘˜è¦
    word_count: int  # å­—æ•¸
    key_points: List[str]  # 3-5 å€‹é—œéµé»
    readability_score: float  # å¯è®€æ€§åˆ†æ•¸ (0-100)
    quality_status: str  # excellent/good/needs_improvement


class SummaryGenerator:
    """AI Overviews æ‘˜è¦ç”Ÿæˆå™¨"""

    def __init__(self):
        self.target_length_min = 50
        self.target_length_max = 70
        self.max_key_points = 5

    def generate_from_article(
        self,
        article_path: str,
        target_keyword: Optional[str] = None
    ) -> SummaryBox:
        """
        å¾æ–‡ç« ç”Ÿæˆ AI Overviews å„ªåŒ–çš„æ‘˜è¦

        Args:
            article_path: æ–‡ç« æª”æ¡ˆè·¯å¾‘
            target_keyword: ç›®æ¨™é—œéµå­—ï¼ˆå¯é¸ï¼‰

        Returns:
            SummaryBox: ç”Ÿæˆçš„æ‘˜è¦æ¡†
        """
        # è®€å–æ–‡ç« 
        content = self._read_article(article_path)

        # æå–æ¨™é¡Œ
        title = self._extract_title(content, target_keyword)

        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_summary(content, target_keyword)

        # æå–é—œéµé»
        key_points = self._extract_key_points(content)

        # è¨ˆç®—å­—æ•¸
        word_count = len(summary)

        # è©•ä¼°å¯è®€æ€§
        readability_score = self._calculate_readability(summary)

        # åˆ¤æ–·å“è³ª
        quality_status = self._assess_quality(
            word_count,
            readability_score,
            key_points
        )

        return SummaryBox(
            title=title,
            summary=summary,
            word_count=word_count,
            key_points=key_points,
            readability_score=readability_score,
            quality_status=quality_status
        )

    def _read_article(self, article_path: str) -> str:
        """è®€å–æ–‡ç« å…§å®¹"""
        with open(article_path, 'r', encoding='utf-8') as f:
            return f.read()

    def _extract_title(self, content: str, keyword: Optional[str]) -> str:
        """
        æå–æˆ–ç”Ÿæˆå•é¡Œå½¢å¼çš„æ¨™é¡Œ
        AI Overviews åå¥½å•ç­”æ ¼å¼
        """
        # å˜—è©¦å¾ frontmatter æå–
        title_match = re.search(r'^title:\s*["\']?(.+?)["\']?\s*$', content, re.MULTILINE)
        if title_match:
            title = title_match.group(1)
        else:
            # å¾ç¬¬ä¸€å€‹ H1 æå–
            h1_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
            title = h1_match.group(1) if h1_match else "æ–‡ç« æ‘˜è¦"

        # å¦‚æœæ¨™é¡Œä¸æ˜¯å•å¥ï¼Œå˜—è©¦è½‰æ›
        if not any(q in title for q in ['ä»€éº¼', 'å¦‚ä½•', 'ç‚ºä»€éº¼', 'æ€éº¼', '?', 'ï¼Ÿ']):
            # æ ¹æ“šé—œéµå­—ç”Ÿæˆå•å¥
            if keyword:
                if 'æ•™å­¸' in title or 'æŒ‡å—' in title:
                    title = f"å¦‚ä½•{keyword}ï¼Ÿ"
                elif 'æ˜¯ä»€éº¼' not in title:
                    title = f"ä»€éº¼æ˜¯{keyword}ï¼Ÿ"

        return title

    def _generate_summary(self, content: str, keyword: Optional[str]) -> str:
        """
        ç”Ÿæˆ 50-70 å­—çš„å¿«é€Ÿæ‘˜è¦

        ç­–ç•¥ï¼š
        1. æå–æ–‡ç« ç¬¬ä¸€æ®µ
        2. æ‰¾åˆ°æ ¸å¿ƒè«–è¿°
        3. ç°¡åŒ–ç‚º 50-70 å­—
        """
        # ç§»é™¤ frontmatter
        content_without_fm = re.sub(r'^---\n.*?\n---\n', '', content, flags=re.DOTALL)

        # æå–ç¬¬ä¸€æ®µï¼ˆé€šå¸¸åŒ…å«æ ¸å¿ƒè³‡è¨Šï¼‰
        paragraphs = [p.strip() for p in content_without_fm.split('\n\n') if p.strip()]

        # éæ¿¾æ‰æ¨™é¡Œå’Œå¤ªçŸ­çš„æ®µè½
        first_meaningful_para = None
        for para in paragraphs:
            # è·³éæ¨™é¡Œ
            if para.startswith('#'):
                continue
            # è·³éå¤ªçŸ­çš„æ®µè½
            if len(para) < 30:
                continue
            # è·³éåœ–ç‰‡ã€é€£çµç­‰
            if para.startswith('![') or para.startswith('[TOC]'):
                continue

            first_meaningful_para = para
            break

        if not first_meaningful_para:
            first_meaningful_para = paragraphs[0] if paragraphs else "ç„¡æ³•æå–æ‘˜è¦"

        # æ¸…ç† markdown æ ¼å¼
        summary = self._clean_markdown(first_meaningful_para)

        # æˆªå–åˆ° 50-70 å­—
        summary = self._truncate_to_target_length(summary)

        return summary

    def _clean_markdown(self, text: str) -> str:
        """ç§»é™¤ markdown æ ¼å¼æ¨™è¨˜"""
        # ç§»é™¤ç²—é«”
        text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
        # ç§»é™¤æ–œé«”
        text = re.sub(r'\*(.+?)\*', r'\1', text)
        # ç§»é™¤é€£çµ
        text = re.sub(r'\[(.+?)\]\(.+?\)', r'\1', text)
        # ç§»é™¤ç¨‹å¼ç¢¼
        text = re.sub(r'`(.+?)`', r'\1', text)
        # ç§»é™¤æ¨™é¡Œç¬¦è™Ÿ
        text = re.sub(r'^#+\s+', '', text)

        return text.strip()

    def _truncate_to_target_length(self, text: str) -> str:
        """
        æˆªå–åˆ°ç›®æ¨™é•·åº¦ï¼ˆ50-70å­—ï¼‰
        ä¿æŒå¥å­å®Œæ•´æ€§
        """
        if len(text) <= self.target_length_max:
            return text

        # å°‹æ‰¾ç¬¬ä¸€å€‹å¥è™Ÿã€å•è™Ÿæˆ–é©šå˜†è™Ÿ
        sentence_ends = []
        for match in re.finditer(r'[ã€‚ï¼ï¼Ÿ.!?]', text):
            pos = match.end()
            if pos >= self.target_length_min:
                sentence_ends.append(pos)

        if sentence_ends:
            # é¸æ“‡æœ€æ¥è¿‘ 60 å­—çš„ä½ç½®
            target = 60
            best_pos = min(sentence_ends, key=lambda x: abs(x - target))

            if best_pos <= self.target_length_max + 10:  # å…è¨±ç¨å¾®è¶…é
                return text[:best_pos]

        # å¦‚æœæ‰¾ä¸åˆ°åˆé©çš„æ–·é»ï¼Œåœ¨ 70 å­—é™„è¿‘æ–·é–‹
        truncated = text[:self.target_length_max]

        # å˜—è©¦åœ¨æœ€å¾Œä¸€å€‹ç©ºæ ¼æˆ–æ¨™é»æ–·é–‹
        last_space = max(
            truncated.rfind('ï¼Œ'),
            truncated.rfind('ã€'),
            truncated.rfind(' ')
        )

        if last_space > self.target_length_min:
            truncated = truncated[:last_space]

        return truncated + '...'

    def _extract_key_points(self, content: str) -> List[str]:
        """
        æå– 3-5 å€‹é—œéµé»
        å„ªå…ˆå¾åˆ—è¡¨å’Œå°æ¨™é¡Œæå–
        """
        key_points = []

        # ç­–ç•¥ 1: å¾ H2 æ¨™é¡Œæå–
        h2_matches = re.findall(r'^##\s+(.+)$', content, re.MULTILINE)
        for h2 in h2_matches[:self.max_key_points]:
            # æ¸…ç†æ¨™é¡Œ
            clean_h2 = self._clean_markdown(h2)
            # ç§»é™¤åºè™Ÿ
            clean_h2 = re.sub(r'^\d+[\.\ã€]\s*', '', clean_h2)
            key_points.append(clean_h2)

        # å¦‚æœ H2 ä¸å¤ ï¼Œå¾åˆ—è¡¨é …æå–
        if len(key_points) < 3:
            list_matches = re.findall(r'^[\-\*]\s+(.+)$', content, re.MULTILINE)
            for item in list_matches:
                if len(key_points) >= self.max_key_points:
                    break

                clean_item = self._clean_markdown(item)
                # éæ¿¾å¤ªçŸ­çš„é …ç›®
                if len(clean_item) < 5:
                    continue
                # é¿å…é‡è¤‡
                if clean_item not in key_points:
                    key_points.append(clean_item)

        return key_points[:self.max_key_points]

    def _calculate_readability(self, text: str) -> float:
        """
        è¨ˆç®—å¯è®€æ€§åˆ†æ•¸ (0-100)

        è€ƒæ…®å› ç´ ï¼š
        - å¥å­é•·åº¦ï¼ˆè¶ŠçŸ­è¶Šå¥½ï¼‰
        - å¸¸ç”¨è©æ¯”ä¾‹ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
        - è¤‡é›œæ¨™é»ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰
        """
        score = 100.0

        # å› ç´  1: å¹³å‡å¥å­é•·åº¦
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', text)
        sentences = [s.strip() for s in sentences if s.strip()]

        if sentences:
            avg_sentence_length = sum(len(s) for s in sentences) / len(sentences)

            # ç†æƒ³å¥å­é•·åº¦ï¼š10-20 å­—
            if avg_sentence_length > 25:
                score -= 15
            elif avg_sentence_length > 20:
                score -= 5

        # å› ç´  2: è¤‡é›œå­—è©ï¼ˆå°ˆæ¥­è¡“èªã€è‹±æ–‡ç­‰ï¼‰
        # ç°¡åŒ–ï¼šæª¢æ¸¬è‹±æ–‡å–®è©å’Œå°ˆæ¥­è¡“èª
        english_words = re.findall(r'[a-zA-Z]{4,}', text)
        if len(english_words) > 3:
            score -= 10

        # å› ç´  3: è¤‡é›œæ¨™é»
        complex_punctuation = len(re.findall(r'[ï¼›ï¼šã€ã€Œã€ã€ã€ã€ã€‘]', text))
        if complex_punctuation > 3:
            score -= 5

        # å› ç´  4: æ•¸å­—å’Œæ•¸æ“šï¼ˆé©é‡å¥½ï¼Œéå¤šä¸å¥½ï¼‰
        numbers = re.findall(r'\d+', text)
        if len(numbers) > 5:
            score -= 5

        return max(0, min(100, score))

    def _assess_quality(
        self,
        word_count: int,
        readability: float,
        key_points: List[str]
    ) -> str:
        """
        è©•ä¼°æ‘˜è¦å“è³ª

        Returns:
            'excellent' | 'good' | 'needs_improvement'
        """
        # æª¢æŸ¥å­—æ•¸
        length_ok = self.target_length_min <= word_count <= self.target_length_max + 10

        # æª¢æŸ¥å¯è®€æ€§
        readability_ok = readability >= 80

        # æª¢æŸ¥é—œéµé»
        key_points_ok = 3 <= len(key_points) <= 5

        # è©•ç´š
        if length_ok and readability_ok and key_points_ok:
            return 'excellent'
        elif length_ok and (readability_ok or key_points_ok):
            return 'good'
        else:
            return 'needs_improvement'

    def generate_markdown_report(
        self,
        summary_box: SummaryBox,
        output_path: Optional[str] = None
    ) -> str:
        """
        ç”Ÿæˆ Markdown æ ¼å¼çš„ AI Overviews å„ªåŒ–å ±å‘Š

        Args:
            summary_box: æ‘˜è¦æ¡†è³‡æ–™
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰

        Returns:
            str: Markdown æ ¼å¼å ±å‘Š
        """
        # ç‹€æ…‹ emoji
        status_emoji = {
            'excellent': 'ğŸŸ¢',
            'good': 'ğŸŸ¡',
            'needs_improvement': 'ğŸ”´'
        }

        # ç”Ÿæˆå ±å‘Š
        report = f"""# AI Overviews æ‘˜è¦å„ªåŒ–å ±å‘Š

## ğŸ“Š æ‘˜è¦æ¡†

### å•é¡Œ/ä¸»é¡Œ
**{summary_box.title}**

### å¿«é€Ÿå›ç­”æ‘˜è¦
{summary_box.summary}

---

## ğŸ“ˆ å“è³ªæŒ‡æ¨™

- **å­—æ•¸**: {summary_box.word_count} å­— (ç›®æ¨™: 50-70)
- **å¯è®€æ€§åˆ†æ•¸**: {summary_box.readability_score:.1f}/100
- **é—œéµé»æ•¸é‡**: {len(summary_box.key_points)} å€‹
- **æ•´é«”å“è³ª**: {status_emoji[summary_box.quality_status]} {summary_box.quality_status.upper()}

---

## ğŸ¯ é—œéµé» ({len(summary_box.key_points)} å€‹)

"""
        # åŠ å…¥é—œéµé»
        for i, point in enumerate(summary_box.key_points, 1):
            report += f"{i}. {point}\n"

        report += "\n---\n\n## âœ… AI Overviews å„ªåŒ–æª¢æŸ¥è¡¨\n\n"

        # æª¢æŸ¥é …ç›®
        length_ok = 50 <= summary_box.word_count <= 80
        readability_ok = summary_box.readability_score >= 80
        key_points_ok = 3 <= len(summary_box.key_points) <= 5

        report += f"- {'âœ…' if length_ok else 'âŒ'} **å­—æ•¸é©ä¸­** (50-70å­—ï¼Œå…è¨±èª¤å·®)\n"
        report += f"- {'âœ…' if readability_ok else 'âŒ'} **å¯è®€æ€§é«˜** (åˆ†æ•¸ >= 80)\n"
        report += f"- {'âœ…' if key_points_ok else 'âŒ'} **é—œéµé»å®Œæ•´** (3-5å€‹)\n"
        report += f"- {'âœ…' if '?' in summary_box.title or 'ï¼Ÿ' in summary_box.title else 'âš ï¸'} **å•ç­”æ ¼å¼** (æ¨™é¡Œç‚ºå•å¥)\n"

        report += "\n---\n\n## ğŸ’¡ å„ªåŒ–å»ºè­°\n\n"

        # æ ¹æ“šå“è³ªæä¾›å»ºè­°
        if summary_box.quality_status == 'excellent':
            report += "ğŸ‰ **æ‘˜è¦å“è³ªå„ªç§€ï¼** å®Œå…¨ç¬¦åˆ AI Overviews å„ªåŒ–æ¨™æº–ã€‚\n\n"
            report += "å»ºè­°ï¼š\n"
            report += "- ç¢ºä¿åœ¨æ–‡ç« é–‹é ­ä½¿ç”¨æ­¤æ‘˜è¦\n"
            report += "- è€ƒæ…®åŠ å…¥ FAQ Schema markup\n"
            report += "- åœ¨ Meta Description ä¸­ä½¿ç”¨é¡ä¼¼çš„ç°¡æ½”è¡¨é”\n"

        elif summary_box.quality_status == 'good':
            report += "ğŸ‘ **æ‘˜è¦å“è³ªè‰¯å¥½**ï¼Œä½†æœ‰æ”¹é€²ç©ºé–“ï¼š\n\n"

            if not length_ok:
                if summary_box.word_count < 50:
                    report += "- âš ï¸ **æ‘˜è¦å¤ªçŸ­**ï¼šè£œå……æ›´å¤šé—œéµè³‡è¨Šï¼Œç›®æ¨™ 50-70 å­—\n"
                else:
                    report += "- âš ï¸ **æ‘˜è¦ç¨é•·**ï¼šç²¾ç°¡è¡¨é”ï¼Œç§»é™¤å†—é¤˜è©å½™\n"

            if not readability_ok:
                report += "- âš ï¸ **å¯è®€æ€§å¯æ”¹é€²**ï¼šä½¿ç”¨æ›´ç°¡å–®çš„è©å½™ï¼Œç¸®çŸ­å¥å­\n"

            if not key_points_ok:
                if len(summary_box.key_points) < 3:
                    report += "- âš ï¸ **é—œéµé»å¤ªå°‘**ï¼šè£œå……åˆ° 3-5 å€‹é—œéµé»\n"
                else:
                    report += "- âš ï¸ **é—œéµé»éå¤š**ï¼šç²¾ç°¡åˆ°æœ€é‡è¦çš„ 3-5 å€‹\n"

        else:  # needs_improvement
            report += "âš ï¸ **æ‘˜è¦éœ€è¦æ”¹é€²**ï¼Œå»ºè­°é‡å¯«ï¼š\n\n"

            report += "**å•é¡Œè¨ºæ–·**ï¼š\n"
            if not length_ok:
                report += f"- å­—æ•¸å•é¡Œï¼šç•¶å‰ {summary_box.word_count} å­—ï¼Œç›®æ¨™ 50-70 å­—\n"
            if not readability_ok:
                report += f"- å¯è®€æ€§å•é¡Œï¼šç•¶å‰ {summary_box.readability_score:.1f} åˆ†ï¼Œç›®æ¨™ >= 80 åˆ†\n"
            if not key_points_ok:
                report += f"- é—œéµé»å•é¡Œï¼šç•¶å‰ {len(summary_box.key_points)} å€‹ï¼Œç›®æ¨™ 3-5 å€‹\n"

            report += "\n**é‡å¯«å»ºè­°**ï¼š\n"
            report += "1. ä½¿ç”¨ç°¡å–®ã€ç›´ç™½çš„èªè¨€\n"
            report += "2. ç¬¬ä¸€å¥è©±ç›´æ¥å›ç­”å•é¡Œ\n"
            report += "3. é¿å…å°ˆæ¥­è¡“èªå’Œè¤‡é›œå¥å¼\n"
            report += "4. ç¢ºä¿é—œéµé»æ¸…æ™°ä¸”å¯æ“ä½œ\n"

        report += "\n---\n\n## ğŸ“š åƒè€ƒè³‡æ–™\n\n"
        report += "- Google AI Overviews åœ¨ 2025 å¹´ 9 æœˆè¦†è“‹ 30% çš„ç¾åœ‹æ¡Œé¢æŸ¥è©¢\n"
        report += "- 99%+ çš„ AI Overviews ä¾†æºä¾†è‡ª Top 10 æœå°‹çµæœ\n"
        report += "- E-E-A-T åœ¨ AI Overviews ä¸­è¢«è¦–ç‚º 'Non-Negotiable'\n"
        report += "- å»ºè­°ä½¿ç”¨ FAQ Schema å¢åŠ è¢«å¼•ç”¨æ©Ÿæœƒ\n"

        report += f"\n---\n\n*å ±å‘Šç”Ÿæˆæ™‚é–“: {self._get_timestamp()}*\n"

        # å¦‚æœæŒ‡å®šè¼¸å‡ºè·¯å¾‘ï¼Œå¯«å…¥æª”æ¡ˆ
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"âœ… AI Overviews å ±å‘Šå·²ç”Ÿæˆ: {output_path}")

        return report

    def _get_timestamp(self) -> str:
        """å–å¾—ç•¶å‰æ™‚é–“æˆ³è¨˜"""
        from datetime import datetime
        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')


def main():
    """å‘½ä»¤è¡Œä»‹é¢"""
    parser = argparse.ArgumentParser(
        description='ç‚º Google AI Overviews ç”Ÿæˆå„ªåŒ–çš„æ‘˜è¦æ¡†'
    )
    parser.add_argument(
        'article',
        help='æ–‡ç« æª”æ¡ˆè·¯å¾‘'
    )
    parser.add_argument(
        '-k', '--keyword',
        help='ç›®æ¨™é—œéµå­—ï¼ˆå¯é¸ï¼‰'
    )
    parser.add_argument(
        '-o', '--output',
        help='è¼¸å‡ºå ±å‘Šè·¯å¾‘ï¼ˆå¯é¸ï¼‰'
    )

    args = parser.parse_args()

    # å‰µå»ºç”Ÿæˆå™¨
    generator = SummaryGenerator()

    # ç”Ÿæˆæ‘˜è¦
    print(f"ğŸ” åˆ†ææ–‡ç« : {args.article}")
    summary_box = generator.generate_from_article(
        args.article,
        args.keyword
    )

    # ç”Ÿæˆå ±å‘Š
    report = generator.generate_markdown_report(
        summary_box,
        args.output
    )

    # å¦‚æœæ²’æœ‰æŒ‡å®šè¼¸å‡ºè·¯å¾‘ï¼Œåˆ—å°åˆ°çµ‚ç«¯
    if not args.output:
        print("\n" + report)

    # é¡¯ç¤ºç‹€æ…‹
    status_emoji = {
        'excellent': 'ğŸŸ¢',
        'good': 'ğŸŸ¡',
        'needs_improvement': 'ğŸ”´'
    }

    print(f"\n{status_emoji[summary_box.quality_status]} æ‘˜è¦å“è³ª: {summary_box.quality_status.upper()}")
    print(f"ğŸ“Š å­—æ•¸: {summary_box.word_count}")
    print(f"ğŸ“ˆ å¯è®€æ€§: {summary_box.readability_score:.1f}/100")


if __name__ == '__main__':
    main()
